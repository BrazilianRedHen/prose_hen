Rethinking the role of automated writing evaluation (AWE) feedback in
The development of language processing technologies and statistical methods has enabled modern automated writing evaluation (AWE) systems to provide feedback on language and content in addition to an automated score.
However, concerns have been raised with regard to the instructional and assessment value of AWE in writing classrooms.
The findings from a few classroom-based studies concerning the impact of AWE on writing instruction and performance are largely inconclusive.
Meanwhile, since research provides favorable evidence for the reliability of AWE corrective feedback, and that writing accuracy is both an important and frustrating issue, it is worthwhile to examine more specifically the impact of AWE corrective feedback on writing accuracy.
Therefore, the study used mixed-methods to investigate how Criterion (R) affected writing instruction and performance.
Results suggested that Criterion (R) has led to increased revisions, and that the corrective feedback from Criterion (R) helped improve accuracy from a rough to a final draft.
The potential benefits were also confirmed by the instructors' interviews.
The students' perspectives were mixed, but the extent to which the views vary may depend on the students' language proficiency level and their instructors' use and perspectives of AWE.
(C) 2014 Elsevier Inc.
All rights reserved.
