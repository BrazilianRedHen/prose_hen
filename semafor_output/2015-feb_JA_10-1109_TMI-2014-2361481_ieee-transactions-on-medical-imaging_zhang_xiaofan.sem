{"frames":[{"target":{"name":"Commerce_buy","spans":[{"start":1,"end":2,"text":"transactions"}]},"annotationSets":[{"rank":0,"score":49.60455483872545,"frameElements":[{"name":"Goods","spans":[{"start":2,"end":5,"text":"on medical imaging"}]}]}]}],"tokens":["Ieee","transactions","on","medical","imaging","."]}
{"frames":[{"target":{"name":"Similarity","spans":[{"start":3,"end":4,"text":"Image"}]},"annotationSets":[{"rank":0,"score":50.95776261619185,"frameElements":[{"name":"Entities","spans":[{"start":2,"end":3,"text":"Histopathological"}]}]}]},{"target":{"name":"Scrutiny","spans":[{"start":4,"end":5,"text":"Analysis"}]},"annotationSets":[{"rank":0,"score":45.02641767993175,"frameElements":[]}]},{"target":{"name":"Similarity","spans":[{"start":7,"end":8,"text":"Image"}]},"annotationSets":[{"rank":0,"score":50.794028072042245,"frameElements":[]}]}],"tokens":["Towards","Large-Scale","Histopathological","Image","Analysis",":","Hashing-Based","Image","Retrieval","."]}
{"frames":[{"target":{"name":"Scrutiny","spans":[{"start":1,"end":2,"text":"analysis"}]},"annotationSets":[{"rank":0,"score":47.64483426655621,"frameElements":[{"name":"Ground","spans":[{"start":2,"end":5,"text":"of histopathological images"}]}]}]},{"target":{"name":"Sensation","spans":[{"start":4,"end":5,"text":"images"}]},"annotationSets":[{"rank":0,"score":32.79740350500748,"frameElements":[]}]},{"target":{"name":"Using","spans":[{"start":8,"end":9,"text":"utilized"}]},"annotationSets":[{"rank":0,"score":88.34329382919675,"frameElements":[]}]},{"target":{"name":"Means","spans":[{"start":12,"end":13,"text":"methods"}]},"annotationSets":[{"rank":0,"score":21.321604371917086,"frameElements":[{"name":"Means","spans":[{"start":12,"end":13,"text":"methods"}]}]}]},{"target":{"name":"Temporal_collocation","spans":[{"start":14,"end":15,"text":"modern"}]},"annotationSets":[{"rank":0,"score":34.65625099033126,"frameElements":[{"name":"Trajector_entity","spans":[{"start":15,"end":16,"text":"machine"}]}]}]},{"target":{"name":"Gizmo","spans":[{"start":15,"end":16,"text":"machine"}]},"annotationSets":[{"rank":0,"score":18.132927986840706,"frameElements":[{"name":"Descriptor","spans":[{"start":14,"end":15,"text":"modern"}]}]}]},{"target":{"name":"Coming_to_believe","spans":[{"start":16,"end":17,"text":"learning"}]},"annotationSets":[{"rank":0,"score":34.05418268124297,"frameElements":[]}]},{"target":{"name":"Means","spans":[{"start":17,"end":18,"text":"techniques"}]},"annotationSets":[{"rank":0,"score":21.048878767429752,"frameElements":[{"name":"Means","spans":[{"start":17,"end":18,"text":"techniques"}]},{"name":"Purpose","spans":[{"start":16,"end":17,"text":"learning"}]}]}]}],"tokens":["Automatic","analysis","of","histopathological","images","has","been","widely","utilized","leveraging","computational","image-processing","methods","and","modern","machine","learning","techniques","."]}
{"frames":[{"target":{"name":"Quantity","spans":[{"start":0,"end":1,"text":"Both"}]},"annotationSets":[{"rank":0,"score":23.844047464458576,"frameElements":[{"name":"Quantity","spans":[{"start":0,"end":1,"text":"Both"}]}]}]},{"target":{"name":"Gizmo","spans":[{"start":12,"end":13,"text":"systems"}]},"annotationSets":[{"rank":0,"score":24.986650971328054,"frameElements":[]}]},{"target":{"name":"Cause_to_make_progress","spans":[{"start":16,"end":17,"text":"developed"}]},"annotationSets":[{"rank":0,"score":75.74747879966444,"frameElements":[{"name":"Time","spans":[{"start":15,"end":16,"text":"successfully"}]},{"name":"Project","spans":[{"start":17,"end":22,"text":"for diagnosis , disease detection"}]}]}]},{"target":{"name":"Medical_conditions","spans":[{"start":20,"end":21,"text":"disease"}]},"annotationSets":[{"rank":0,"score":33.88193142037607,"frameElements":[]}]},{"target":{"name":"Deciding","spans":[{"start":24,"end":25,"text":"decision"}]},"annotationSets":[{"rank":0,"score":16.381758991325125,"frameElements":[]}]},{"target":{"name":"Taking_sides","spans":[{"start":25,"end":26,"text":"support"}]},"annotationSets":[{"rank":0,"score":54.04472159758269,"frameElements":[{"name":"Cognizer","spans":[{"start":24,"end":25,"text":"decision"}]}]}]},{"target":{"name":"Locale","spans":[{"start":28,"end":29,"text":"area"}]},"annotationSets":[{"rank":0,"score":47.22835410984553,"frameElements":[{"name":"Locale","spans":[{"start":28,"end":29,"text":"area"}]}]}]}],"tokens":["Both","computer-aided","diagnosis","-LRB-","CAD","-RRB-","and","content-based","image-retrieval","-LRB-","CBIR","-RRB-","systems","have","been","successfully","developed","for","diagnosis",",","disease","detection",",","and","decision","support","in","this","area","."]}
{"frames":[{"target":{"name":"Temporal_collocation","spans":[{"start":0,"end":1,"text":"Recently"}]},"annotationSets":[{"rank":0,"score":31.192697539643195,"frameElements":[]}]},{"target":{"name":"Quantity","spans":[{"start":5,"end":6,"text":"amount"}]},"annotationSets":[{"rank":0,"score":20.962858384298215,"frameElements":[{"name":"Q_Prop","spans":[{"start":4,"end":5,"text":"ever-increasing"}]},{"name":"Quantity","spans":[{"start":5,"end":6,"text":"amount"}]},{"name":"Mass","spans":[{"start":6,"end":15,"text":"of annotated medical data , large-scale and data-driven methods"}]}]}]},{"target":{"name":"Means","spans":[{"start":14,"end":15,"text":"methods"}]},"annotationSets":[{"rank":0,"score":21.219198612957648,"frameElements":[{"name":"Means","spans":[{"start":14,"end":15,"text":"methods"}]},{"name":"Purpose","spans":[{"start":11,"end":14,"text":"large-scale and data-driven"}]}]}]},{"target":{"name":"Coming_to_be","spans":[{"start":16,"end":17,"text":"emerged"}]},"annotationSets":[{"rank":0,"score":42.39945149047153,"frameElements":[{"name":"Entity","spans":[{"start":6,"end":15,"text":"of annotated medical data , large-scale and data-driven methods"}]}]}]},{"target":{"name":"Offering","spans":[{"start":18,"end":19,"text":"offer"}]},"annotationSets":[{"rank":0,"score":10.073092658052989,"frameElements":[{"name":"Theme","spans":[{"start":19,"end":31,"text":"a promise of bridging the semantic gap between images and diagnostic information"}]}]}]},{"target":{"name":"Commitment","spans":[{"start":20,"end":21,"text":"promise"}]},"annotationSets":[{"rank":0,"score":34.483308567830036,"frameElements":[{"name":"Message","spans":[{"start":21,"end":31,"text":"of bridging the semantic gap between images and diagnostic information"}]}]}]},{"target":{"name":"Natural_features","spans":[{"start":25,"end":26,"text":"gap"}]},"annotationSets":[{"rank":0,"score":32.73682331474886,"frameElements":[{"name":"Locale","spans":[{"start":25,"end":26,"text":"gap"}]}]}]},{"target":{"name":"Sensation","spans":[{"start":27,"end":28,"text":"images"}]},"annotationSets":[{"rank":0,"score":37.25342265947456,"frameElements":[]}]},{"target":{"name":"Information","spans":[{"start":30,"end":31,"text":"information"}]},"annotationSets":[{"rank":0,"score":23.81204996575189,"frameElements":[{"name":"Information","spans":[{"start":30,"end":31,"text":"information"}]}]}]}],"tokens":["Recently",",","with","the","ever-increasing","amount","of","annotated","medical","data",",","large-scale","and","data-driven","methods","have","emerged","to","offer","a","promise","of","bridging","the","semantic","gap","between","images","and","diagnostic","information","."]}
{"frames":[{"target":{"name":"Place_weight_on","spans":[{"start":5,"end":6,"text":"focus"}]},"annotationSets":[{"rank":0,"score":56.89231437869856,"frameElements":[{"name":"Consideration","spans":[{"start":6,"end":18,"text":"on developing scalable image-retrieval techniques to cope intelligently with massive histopathological images"}]},{"name":"Agent","spans":[{"start":4,"end":5,"text":"we"}]}]}]},{"target":{"name":"Cause_to_make_progress","spans":[{"start":7,"end":8,"text":"developing"}]},"annotationSets":[{"rank":0,"score":84.73914674781895,"frameElements":[{"name":"Agent","spans":[{"start":4,"end":5,"text":"we"}]},{"name":"Project","spans":[{"start":8,"end":18,"text":"scalable image-retrieval techniques to cope intelligently with massive histopathological images"}]}]}]},{"target":{"name":"Means","spans":[{"start":10,"end":11,"text":"techniques"}]},"annotationSets":[{"rank":0,"score":23.09959161416011,"frameElements":[{"name":"Means","spans":[{"start":10,"end":11,"text":"techniques"}]},{"name":"Purpose","spans":[{"start":11,"end":18,"text":"to cope intelligently with massive histopathological images"}]}]}]},{"target":{"name":"Clothing","spans":[{"start":12,"end":13,"text":"cope"}]},"annotationSets":[{"rank":0,"score":31.42577325507823,"frameElements":[]}]},{"target":{"name":"Dimension","spans":[{"start":15,"end":16,"text":"massive"}]},"annotationSets":[{"rank":0,"score":24.55302703551162,"frameElements":[{"name":"Object","spans":[{"start":17,"end":18,"text":"images"}]},{"name":"Dimension","spans":[{"start":15,"end":16,"text":"massive"}]}]}]},{"target":{"name":"Sensation","spans":[{"start":17,"end":18,"text":"images"}]},"annotationSets":[{"rank":0,"score":35.02691765230459,"frameElements":[]}]}],"tokens":["In","this","paper",",","we","focus","on","developing","scalable","image-retrieval","techniques","to","cope","intelligently","with","massive","histopathological","images","."]}
{"frames":[{"target":{"name":"Presence","spans":[{"start":3,"end":4,"text":"present"}]},"annotationSets":[{"rank":0,"score":8.64402593897249,"frameElements":[{"name":"Entity","spans":[{"start":2,"end":3,"text":"we"}]}]}]},{"target":{"name":"Means","spans":[{"start":8,"end":9,"text":"technique"}]},"annotationSets":[{"rank":0,"score":19.46780589911226,"frameElements":[{"name":"Means","spans":[{"start":9,"end":10,"text":"which"}]}]}]},{"target":{"name":"Dimension","spans":[{"start":12,"end":13,"text":"small"}]},"annotationSets":[{"rank":0,"score":21.020623569146494,"frameElements":[{"name":"Object","spans":[{"start":13,"end":14,"text":"amount"}]},{"name":"Dimension","spans":[{"start":12,"end":13,"text":"small"}]}]}]},{"target":{"name":"Quantity","spans":[{"start":13,"end":14,"text":"amount"}]},"annotationSets":[{"rank":0,"score":22.011546754632676,"frameElements":[{"name":"Q_Prop","spans":[{"start":12,"end":13,"text":"small"}]},{"name":"Quantity","spans":[{"start":13,"end":14,"text":"amount"}]},{"name":"Mass","spans":[{"start":14,"end":17,"text":"of supervised information"}]}]}]},{"target":{"name":"Information","spans":[{"start":16,"end":17,"text":"information"}]},"annotationSets":[{"rank":0,"score":25.49480653118122,"frameElements":[{"name":"Information","spans":[{"start":16,"end":17,"text":"information"}]}]}]},{"target":{"name":"Education_teaching","spans":[{"start":18,"end":19,"text":"learning"}]},"annotationSets":[{"rank":0,"score":98.5554090189368,"frameElements":[]}]},{"target":{"name":"Cardinal_numbers","spans":[{"start":22,"end":23,"text":"10"}]},"annotationSets":[{"rank":0,"score":27.753172167204937,"frameElements":[{"name":"Number","spans":[{"start":22,"end":23,"text":"10"}]},{"name":"Entity","spans":[{"start":24,"end":25,"text":"image"}]}]}]},{"target":{"name":"Similarity","spans":[{"start":24,"end":25,"text":"image"}]},"annotationSets":[{"rank":0,"score":48.68817532610555,"frameElements":[]}]},{"target":{"name":"Experiencer_focus","spans":[{"start":25,"end":26,"text":"feature"}]},"annotationSets":[{"rank":0,"score":52.933842913046256,"frameElements":[{"name":"Content","spans":[{"start":26,"end":27,"text":"vector"}]},{"name":"Experiencer","spans":[{"start":8,"end":25,"text":"technique which leverages a small amount of supervised information in learning to compress a 10 000-dimensional image"}]}]}]},{"target":{"name":"Sole_instance","spans":[{"start":28,"end":29,"text":"only"}]},"annotationSets":[{"rank":0,"score":4.79816898569179,"frameElements":[{"name":"Type","spans":[{"start":29,"end":30,"text":"tens"}]}]}]},{"target":{"name":"Distinctiveness","spans":[{"start":36,"end":37,"text":"signatures"}]},"annotationSets":[{"rank":0,"score":16.470251664224755,"frameElements":[{"name":"Entity","spans":[{"start":35,"end":36,"text":"informative"}]}]}]},{"target":{"name":"Preserving","spans":[{"start":37,"end":38,"text":"preserved"}]},"annotationSets":[{"rank":0,"score":33.12324923210761,"frameElements":[]}]}],"tokens":["Specifically",",","we","present","a","supervised","kernel","hashing","technique","which","leverages","a","small","amount","of","supervised","information","in","learning","to","compress","a","10","000-dimensional","image","feature","vector","into","only","tens","of","binary","bits","with","the","informative","signatures","preserved","."]}
{"frames":[{"target":{"name":"Being_named","spans":[{"start":2,"end":3,"text":"codes"}]},"annotationSets":[{"rank":0,"score":20.009226765316857,"frameElements":[{"name":"Entity","spans":[{"start":0,"end":3,"text":"These binary codes"}]}]}]},{"target":{"name":"Temporal_collocation","spans":[{"start":4,"end":5,"text":"then"}]},"annotationSets":[{"rank":0,"score":26.575402604558445,"frameElements":[{"name":"Trajector_event","spans":[{"start":0,"end":3,"text":"These binary codes"}]}]}]},{"target":{"name":"Sensation","spans":[{"start":15,"end":16,"text":"images"}]},"annotationSets":[{"rank":0,"score":36.43214826072399,"frameElements":[]}]},{"target":{"name":"Dimension","spans":[{"start":18,"end":19,"text":"large"}]},"annotationSets":[{"rank":0,"score":23.299740067930163,"frameElements":[{"name":"Object","spans":[{"start":19,"end":20,"text":"database"}]},{"name":"Dimension","spans":[{"start":18,"end":19,"text":"large"}]}]}]}],"tokens":["These","binary","codes","are","then","indexed","into","a","hash","table","that","enables","real-time","retrieval","of","images","in","a","large","database","."]}
{"frames":[{"target":{"name":"Information","spans":[{"start":4,"end":5,"text":"information"}]},"annotationSets":[{"rank":0,"score":25.322317398412213,"frameElements":[{"name":"Information","spans":[{"start":4,"end":5,"text":"information"}]}]}]},{"target":{"name":"Employing","spans":[{"start":6,"end":7,"text":"employed"}]},"annotationSets":[{"rank":0,"score":49.074087024845106,"frameElements":[{"name":"Employee","spans":[{"start":4,"end":5,"text":"information"}]}]}]},{"target":{"name":"Natural_features","spans":[{"start":11,"end":12,"text":"gap"}]},"annotationSets":[{"rank":0,"score":32.85043029728756,"frameElements":[{"name":"Locale","spans":[{"start":11,"end":12,"text":"gap"}]}]}]},{"target":{"name":"Similarity","spans":[{"start":14,"end":15,"text":"image"}]},"annotationSets":[{"rank":0,"score":50.794028072042245,"frameElements":[]}]},{"target":{"name":"Information","spans":[{"start":19,"end":20,"text":"information"}]},"annotationSets":[{"rank":0,"score":24.279345759472577,"frameElements":[{"name":"Information","spans":[{"start":19,"end":20,"text":"information"}]}]}]}],"tokens":["Critically",",","the","supervised","information","is","employed","to","bridge","the","semantic","gap","between","low-level","image","features","and","high-level","diagnostic","information","."]}
{"frames":[{"target":{"name":"Building","spans":[{"start":1,"end":2,"text":"build"}]},"annotationSets":[{"rank":0,"score":91.28953851529677,"frameElements":[{"name":"Created_entity","spans":[{"start":2,"end":6,"text":"a scalable image-retrieval framework"}]},{"name":"Agent","spans":[{"start":0,"end":1,"text":"We"}]}]}]},{"target":{"name":"Means","spans":[{"start":11,"end":12,"text":"technique"}]},"annotationSets":[{"rank":0,"score":18.43663299994377,"frameElements":[{"name":"Means","spans":[{"start":11,"end":12,"text":"technique"}]},{"name":"Purpose","spans":[{"start":10,"end":11,"text":"hashing"}]}]}]},{"target":{"name":"Performing_arts","spans":[{"start":15,"end":16,"text":"performance"}]},"annotationSets":[{"rank":0,"score":5.701600185106868,"frameElements":[]}]},{"target":{"name":"Quantity","spans":[{"start":17,"end":18,"text":"several"}]},"annotationSets":[{"rank":0,"score":25.45679427103348,"frameElements":[{"name":"Quantity","spans":[{"start":17,"end":18,"text":"several"}]}]}]},{"target":{"name":"Cardinal_numbers","spans":[{"start":18,"end":19,"text":"thousand"}]},"annotationSets":[{"rank":0,"score":21.16170896502996,"frameElements":[{"name":"Number","spans":[{"start":18,"end":19,"text":"thousand"}]},{"name":"Entity","spans":[{"start":20,"end":21,"text":"images"}]}]}]},{"target":{"name":"Sensation","spans":[{"start":20,"end":21,"text":"images"}]},"annotationSets":[{"rank":0,"score":33.246503513958324,"frameElements":[]}]},{"target":{"name":"Getting","spans":[{"start":21,"end":22,"text":"acquired"}]},"annotationSets":[{"rank":0,"score":57.014093126398734,"frameElements":[{"name":"Source","spans":[{"start":22,"end":26,"text":"from breast microscopic tissues"}]},{"name":"Theme","spans":[{"start":17,"end":21,"text":"several thousand histopathological images"}]}]}]},{"target":{"name":"Observable_body_parts","spans":[{"start":23,"end":24,"text":"breast"}]},"annotationSets":[{"rank":0,"score":24.494956114929398,"frameElements":[{"name":"Body_part","spans":[{"start":23,"end":24,"text":"breast"}]}]}]}],"tokens":["We","build","a","scalable","image-retrieval","framework","based","on","the","supervised","hashing","technique","and","validate","its","performance","on","several","thousand","histopathological","images","acquired","from","breast","microscopic","tissues","."]}
{"frames":[{"target":{"name":"Intentionally_act","spans":[{"start":3,"end":5,"text":"carried out"}]},"annotationSets":[{"rank":0,"score":65.98185452727208,"frameElements":[{"name":"Act","spans":[{"start":0,"end":2,"text":"Extensive evaluations"}]}]}]},{"target":{"name":"Assessing","spans":[{"start":1,"end":2,"text":"evaluations"}]},"annotationSets":[{"rank":0,"score":93.67329052695445,"frameElements":[{"name":"Assessor","spans":[{"start":0,"end":2,"text":"Extensive evaluations"}]}]}]},{"target":{"name":"Simple_name","spans":[{"start":6,"end":7,"text":"terms"}]},"annotationSets":[{"rank":0,"score":11.850119130173365,"frameElements":[{"name":"Entity","spans":[{"start":7,"end":21,"text":"of image classification -LRB- i.e. , benign versus actionable categorization -RRB- and retrieval tests"}]}]}]},{"target":{"name":"Similarity","spans":[{"start":8,"end":9,"text":"image"}]},"annotationSets":[{"rank":0,"score":53.41938486523525,"frameElements":[]}]},{"target":{"name":"Categorization","spans":[{"start":9,"end":10,"text":"classification"}]},"annotationSets":[{"rank":0,"score":36.19903312057219,"frameElements":[]}]},{"target":{"name":"Natural_features","spans":[{"start":15,"end":16,"text":"actionable"}]},"annotationSets":[{"rank":0,"score":32.969419687592946,"frameElements":[{"name":"Locale","spans":[{"start":16,"end":17,"text":"categorization"}]}]}]},{"target":{"name":"Categorization","spans":[{"start":16,"end":17,"text":"categorization"}]},"annotationSets":[{"rank":0,"score":35.95840576780015,"frameElements":[]}]},{"target":{"name":"Operational_testing","spans":[{"start":20,"end":21,"text":"tests"}]},"annotationSets":[{"rank":0,"score":74.97449936588923,"frameElements":[]}]}],"tokens":["Extensive","evaluations","are","carried","out","in","terms","of","image","classification","-LRB-","i.e.",",","benign","versus","actionable","categorization","-RRB-","and","retrieval","tests","."]}
{"frames":[{"target":{"name":"Accomplishment","spans":[{"start":2,"end":3,"text":"achieves"}]},"annotationSets":[{"rank":0,"score":66.51169001082056,"frameElements":[{"name":"Goal","spans":[{"start":3,"end":14,"text":"about 88.1 % classification accuracy as well as promising time efficiency"}]},{"name":"Agent","spans":[{"start":0,"end":2,"text":"Our framework"}]}]}]},{"target":{"name":"Relational_quantity","spans":[{"start":3,"end":4,"text":"about"}]},"annotationSets":[{"rank":0,"score":12.912281846278947,"frameElements":[{"name":"Reference_quantity","spans":[{"start":4,"end":5,"text":"88.1"}]},{"name":"Denoted_quantity","spans":[{"start":3,"end":4,"text":"about"}]}]}]},{"target":{"name":"Categorization","spans":[{"start":6,"end":7,"text":"classification"}]},"annotationSets":[{"rank":0,"score":35.99085886612369,"frameElements":[{"name":"Item","spans":[{"start":7,"end":8,"text":"accuracy"}]}]}]},{"target":{"name":"Trust","spans":[{"start":7,"end":8,"text":"accuracy"}]},"annotationSets":[{"rank":0,"score":17.734657636428455,"frameElements":[]}]},{"target":{"name":"Omen","spans":[{"start":11,"end":12,"text":"promising"}]},"annotationSets":[{"rank":0,"score":29.72335218523301,"frameElements":[]}]},{"target":{"name":"Measure_duration","spans":[{"start":12,"end":13,"text":"time"}]},"annotationSets":[{"rank":0,"score":17.015481676120242,"frameElements":[{"name":"Unit","spans":[{"start":12,"end":13,"text":"time"}]}]}]}],"tokens":["Our","framework","achieves","about","88.1","%","classification","accuracy","as","well","as","promising","time","efficiency","."]}
{"frames":[{"target":{"name":"Instance","spans":[{"start":1,"end":2,"text":"example"}]},"annotationSets":[{"rank":0,"score":10.812753721214584,"frameElements":[{"name":"Instance","spans":[{"start":1,"end":2,"text":"example"}]}]}]},{"target":{"name":"Capability","spans":[{"start":5,"end":6,"text":"can"}]},"annotationSets":[{"rank":0,"score":46.45832857937494,"frameElements":[{"name":"Event","spans":[{"start":6,"end":7,"text":"execute"}]},{"name":"Entity","spans":[{"start":3,"end":5,"text":"the framework"}]}]}]},{"target":{"name":"Execution","spans":[{"start":6,"end":7,"text":"execute"}]},"annotationSets":[{"rank":0,"score":34.26183570537701,"frameElements":[]}]},{"target":{"name":"Questioning","spans":[{"start":9,"end":10,"text":"queries"}]},"annotationSets":[{"rank":0,"score":36.68437313358091,"frameElements":[]}]},{"target":{"name":"Sole_instance","spans":[{"start":11,"end":12,"text":"only"}]},"annotationSets":[{"rank":0,"score":4.104015678711471,"frameElements":[{"name":"Type","spans":[{"start":12,"end":13,"text":"0.01"}]}]}]},{"target":{"name":"Evaluative_comparison","spans":[{"start":15,"end":16,"text":"comparing"}]},"annotationSets":[{"rank":0,"score":26.42877673392926,"frameElements":[]}]},{"target":{"name":"Increment","spans":[{"start":18,"end":19,"text":"other"}]},"annotationSets":[{"rank":0,"score":15.837366183742486,"frameElements":[]}]},{"target":{"name":"Using","spans":[{"start":20,"end":21,"text":"used"}]},"annotationSets":[{"rank":0,"score":99.75050126991128,"frameElements":[{"name":"Instrument","spans":[{"start":19,"end":20,"text":"commonly"}]}]}]},{"target":{"name":"Cause_expansion","spans":[{"start":22,"end":23,"text":"reduction"}]},"annotationSets":[{"rank":0,"score":63.36740576293082,"frameElements":[]}]},{"target":{"name":"Experiencer_focus","spans":[{"start":24,"end":25,"text":"feature"}]},"annotationSets":[{"rank":0,"score":46.49711666154147,"frameElements":[{"name":"Content","spans":[{"start":25,"end":27,"text":"selection methods"}]},{"name":"Experiencer","spans":[{"start":3,"end":5,"text":"the framework"}]}]}]},{"target":{"name":"Choosing","spans":[{"start":25,"end":26,"text":"selection"}]},"annotationSets":[{"rank":0,"score":32.71819856373441,"frameElements":[]}]},{"target":{"name":"Means","spans":[{"start":26,"end":27,"text":"methods"}]},"annotationSets":[{"rank":0,"score":22.69898845015912,"frameElements":[{"name":"Means","spans":[{"start":26,"end":27,"text":"methods"}]},{"name":"Purpose","spans":[{"start":25,"end":26,"text":"selection"}]}]}]}],"tokens":["For","example",",","the","framework","can","execute","around","800","queries","in","only","0.01","s",",","comparing","favorably","with","other","commonly","used","dimensionality","reduction","and","feature","selection","methods","."]}
