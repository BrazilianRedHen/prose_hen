{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Biblioteca de suporte de arrays e matriz multidimensionais\n",
    "import pandas as pd #Biblioteca de manipulação e análise de dado\n",
    "import os #Esse modulo prove alguns metodos para atuar com o sistema operacional, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import sys #Esse modulo prove acesso à algumas variaveis de sistema, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import matplotlib.pyplot as plt #Biblioteca padrão pala plotagem de graficos\n",
    "import seaborn as sns #Biblioteca para melhoria de interface dos graficos\n",
    "sys.path.append('../abstract_normalizer')\n",
    "import dictionaries\n",
    "import json\n",
    "import operator\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that removes files that have especified extensions from a list of files 'li'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDirectory(li):\n",
    "    try:\n",
    "        for directory in li:\n",
    "            if(not directory.endswith(\".json\") ):\n",
    "                li.remove(directory)\n",
    "                cleanDirectory(li)\n",
    "    except:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that gets all the fields, disciplines and journalsof the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllFields():\n",
    "    return {\n",
    "    \"AGRONOMY\", \n",
    "    \"BUSINESS\", \n",
    "    \"CHEMISTRY\", \n",
    "    \"COGNITIVE LINGUISTICS\",\n",
    "    \"COMPUTER SCIENCE\",\n",
    "    \"ENGINEERING\", \n",
    "    \"HEALTH CARE SCIENCES & SERVICES\", \n",
    "    \"LINGUISTICS\", \n",
    "    \"PHYSICS\", \n",
    "    \"TELECOMMUNICATIONS\"\n",
    "    }\n",
    "\n",
    "def getAllDisciplines():\n",
    "    return {\n",
    "            \"BIOLOGICAL SCIENCES\",\n",
    "            \"SOCIAL & HUMAN SCIENCES\",\n",
    "            \"HARD SCIENCES\"\n",
    "    }\n",
    "\n",
    "def getAllJournals():\n",
    "    return {\n",
    "    \"ACADEMIC MEDICINE\",\n",
    "    \"ACADEMY OF MANAGEMENT ANNALS\" ,\n",
    "    \"ACADEMY OF MANAGEMENT REVIEW\" ,\n",
    "    \"ADVANCED MATERIALS\" ,\n",
    "    \"ADVANCES IN AGRONOMY, VOL 129\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 130\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 131\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 132\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 133\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 134\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 135\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 136\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 137\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 138\",\n",
    "    \"ADVANCES IN AGRONOMY, VOL 139\",\n",
    "    \"AGRICULTURAL AND FOREST METEOROLOGY\",\n",
    "    \"AGRONOMY FOR SUSTAINABLE DEVELOPMENT\",\n",
    "    \"ANNUAL REVIEW OF APPLIED LINGUISTICS\",\n",
    "    \"APPLIED LINGUISTICS\",\n",
    "    \"ARCHIVES OF COMPUTATIONAL METHODS IN ENGINEERING\",\n",
    "    \"BMJ QUALITY & SAFETY\",\n",
    "    \"BRAIN AND LANGUAGE\",\n",
    "    \"CHEMICAL REVIEWS\" ,\n",
    "    \"CHEMICAL SOCIETY REVIEWS\" ,\n",
    "    \"COGNITIVE LINGUISTICS\" ,\n",
    "    \"COMBUSTION AND FLAME\",\n",
    "    \"COMPOSITES PART B ENGINEERING\",\n",
    "    \"COMPUTER AIDED CIVIL AND INFRASTRUCTURE ENGINEERING\",\n",
    "    \"COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING\",\n",
    "    \"ENERGY & ENVIRONMENTAL SCIENCE\" ,\n",
    "    \"GLOBAL CHANGE BIOLOGY BIOENERGY\",\n",
    "    \"HEALTH AFFAIRS\",\n",
    "    \"IEEE COMMUNICATIONS MAGAZINE\",\n",
    "    \"IEEE COMMUNICATIONS SURVEYS AND TUTORIALS\",\n",
    "    \"IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS\",\n",
    "    \"IEEE NETWORK\",\n",
    "    \"IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS\",\n",
    "    \"IEEE TRANSACTIONS ON MEDICAL IMAGING\",\n",
    "    \"IEEE WIRELESS COMMUNICATIONS\",\n",
    "    \"INTERNATIONAL JOURNAL OF ENGINEERING SCIENCE\",\n",
    "    \"JOURNAL OF MANAGEMENT\" ,\n",
    "    \"JOURNAL OF MARKETING\" ,\n",
    "    \"JOURNAL OF MEMORY AND LANGUAGE\",\n",
    "    \"JOURNAL OF SECOND LANGUAGE WRITING\",\n",
    "    \"JOURNAL OF STATISTICAL SOFTWARE\",\n",
    "    \"JOURNAL OF THE ACADEMY OF MARKETING SCIENCE\" ,\n",
    "    \"MEDICAL IMAGE ANALYSIS\",\n",
    "    \"MILBANK QUARTERLY\",\n",
    "    \"MODERN LANGUAGE JOURNAL\",\n",
    "    \"NATURE CHEMISTRY\" ,\n",
    "    \"NATURE PHYSICS\" ,\n",
    "    \"PHYSICAL REVIEW X\" ,\n",
    "    \"PHYSICS REPORTS REVIEW SECTION OF PHYSICS LETTERS\" ,\n",
    "    \"QUALITY & SAFETY\" ,\n",
    "    \"REPORTS ON PROGRESS IN PHYSICS\" ,\n",
    "    \"REVIEW OF COGNITIVE LINGUISTICS\" ,\n",
    "    \"REVIEWS OF MODERN PHYSICS\" ,\n",
    "    \"THEORETICAL AND APPLIED GENETICS\",\n",
    "    \"VALUE IN HEALTH\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that gets the Title of the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTitle(title):\n",
    "    txtFiles = list()\n",
    "    for (dirpath, dirnames, filenames) in os.walk(\"../raw\"):\n",
    "        txtFiles += [os.path.join(dirpath, file) for file in filenames]\n",
    "\n",
    "    for txtFile in txtFiles:\n",
    "        if txtFile.endswith(\".txt\"):\n",
    "            for line in list(open(txtFile)):\n",
    "                if(line.startswith(\"TI \")):\n",
    "                    nextline = list(open(txtFile))[list(open(txtFile)).index(line)+1];\n",
    "                    if(not nextline.startswith(\"SO \")):\n",
    "                        fileTitle = line.replace(\"TI \",\"\").replace(\"\\n\",\" \").replace(\"  \",\" \")+\" \".join(nextline.split())\n",
    "                    else:\n",
    "                        fileTitle = line.replace(\"TI \",\"\").replace(\"\\n\",\" \")\n",
    "                    if(fileTitle == title):\n",
    "                        return fileTitle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Functions that get the Journal based on a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchJournal(file1,file2):\n",
    "    retorno = \"\"\n",
    "    for j in getAllJournals():\n",
    "        if(file1.find(j) != -1):\n",
    "            retorno = file1\n",
    "        elif(file2.find(j) != -1):\n",
    "            retorno = file2\n",
    "        elif( (file2.find(j) != -1) and (file1.find(j) != -1) ):\n",
    "            retorno = \"False\"\n",
    "    return retorno\n",
    "\n",
    "def getJournal(file):\n",
    "    file = file.split('.seg.json')[0]\n",
    "    file1 = file.split('_')[-3].replace('-',' ').upper()\n",
    "    file2 = file.split('_')[-2].replace('-',' ').upper()\n",
    "    journal = searchJournal(file1,file2)\n",
    "    return journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that gets Abstract's info (journal, field, discipline) from a json file 'file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfoFromFile(file):\n",
    "            fields = dictionaries.dictionaryFields()\n",
    "            disciplines = dictionaries.dictionaryDisciplines()\n",
    "            journals = getAllJournals() \n",
    "            journal = \"\"\n",
    "            \n",
    "            journal = getJournal(file)    \n",
    "            \n",
    "            field = fields.get(journal)\n",
    "            discipline = disciplines.get(field)\n",
    "            abstract = dict()\n",
    "            abstract['journal'] = journal\n",
    "            abstract['field']   = field\n",
    "            abstract['discipline'] = discipline\n",
    "            abstract['all'] = 'all'\n",
    "            return abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that orders a dict with index:values by values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortDict(d):\n",
    "    lista  = (sorted(d.items(), key = lambda x : x[1], reverse=True))\n",
    "    retorno = dict()\n",
    "    for value in lista:\n",
    "        retorno[value[0]] = value[1]\n",
    "    return retorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that receives a dict with indexes:values and returns a dict with only the 30 heighest values in the parameter dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first30(pdict):\n",
    "    d = pdict.copy()\n",
    "    labels = list(d.keys())\n",
    "    counter = 0\n",
    "    for l in labels:\n",
    "        if(counter>=30):\n",
    "            d.pop(l)\n",
    "        counter += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that plots charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateChart(d, opt, info, optdir):\n",
    "    \n",
    "    dic = d\n",
    "    \n",
    "    #selecting only the 30 frames with more occurrence\n",
    "    dic = first30(dic)\n",
    "    \n",
    "    #setting the data that will appear in the chart\n",
    "    labels = list(dic.keys())\n",
    "    values = list(dic.values())\n",
    "    index = np.arange(len(labels))\n",
    "    \n",
    "    #used to allow xaxis locators settings\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    #plotting bar chart\n",
    "    ax.barh(index, values)\n",
    "    \n",
    "    #setting labels\n",
    "    if(optdir == 'frame'):\n",
    "        plt.ylabel('Frames', fontsize=5)\n",
    "    elif(optdir == 'lexical_unit'):\n",
    "        plt.ylabel('Lexical Units', fontsize=5)\n",
    "\n",
    "    plt.xlabel('Occurrences', fontsize=5)\n",
    "    \n",
    "    plt.yticks(index, labels, fontsize=5, rotation=0)\n",
    "    \n",
    "    major = 10\n",
    "    minor = 1\n",
    "    bigger = max(values)\n",
    "    if(bigger > 10):\n",
    "        major = bigger/10\n",
    "        major = math.ceil(major)\n",
    "        while(major % 10 != 0):\n",
    "            major = major+1\n",
    "        minor = major/10\n",
    "    else:\n",
    "        major = 2\n",
    "        minor = 1\n",
    "    \n",
    "    #configuring xtick Major and minor locators\n",
    "    mlocatormax = MultipleLocator(major)\n",
    "    mlocatormin = MultipleLocator(minor)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mlocatormax)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))\n",
    "    ax.xaxis.set_minor_locator(mlocatormin)\n",
    "    ax.xaxis.set_view_interval(0,bigger+major)\n",
    "    \n",
    "    #setting locators size\n",
    "    ax.tick_params(axis='x', which='major', labelsize=6)\n",
    "    ax.tick_params(axis='y', which='major', labelsize=5)\n",
    "    \n",
    "    if(info == 'all'):\n",
    "        info = 'All Corpus'\n",
    "        \n",
    "    plt.title(info)\n",
    "    \n",
    "    if(optdir == 'frame'):\n",
    "        plt.savefig('export/'+opt+'/frame/'+info+'.png', bbox_inches='tight', dpi=300)\n",
    "    elif(optdir == 'lexical_unit'):\n",
    "        plt.savefig('export/'+opt+'/lexical_unit/'+info+'.png', bbox_inches='tight', dpi=300)\n",
    "        \n",
    "    #plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that creates the directories where charts will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirectories():\n",
    "    if not os.path.exists('export'):\n",
    "        os.mkdir('export')\n",
    "\n",
    "    if not os.path.exists('export/field'):\n",
    "        os.mkdir('export/field')\n",
    "\n",
    "    if not os.path.exists('export/discipline'):\n",
    "        os.mkdir('export/discipline')\n",
    "\n",
    "    if not os.path.exists('export/journal'):\n",
    "        os.mkdir('export/journal')\n",
    "\n",
    "    if not os.path.exists('export/all'):\n",
    "        os.mkdir('export/all')\n",
    "        \n",
    "    if not os.path.exists('export/field/frame'):\n",
    "        os.mkdir('export/field/frame')\n",
    "\n",
    "    if not os.path.exists('export/discipline/frame'):\n",
    "        os.mkdir('export/discipline/frame')\n",
    "\n",
    "    if not os.path.exists('export/journal/frame'):\n",
    "        os.mkdir('export/journal/frame')\n",
    "\n",
    "    if not os.path.exists('export/all/frame'):\n",
    "        os.mkdir('export/all/frame')\n",
    "\n",
    "    if not os.path.exists('export/field/lexical_unit'):\n",
    "        os.mkdir('export/field/lexical_unit')\n",
    "\n",
    "    if not os.path.exists('export/discipline/lexical_unit'):\n",
    "        os.mkdir('export/discipline/lexical_unit')\n",
    "\n",
    "    if not os.path.exists('export/journal/lexical_unit'):\n",
    "        os.mkdir('export/journal/lexical_unit')\n",
    "\n",
    "    if not os.path.exists('export/all/lexical_unit'):\n",
    "        os.mkdir('export/all/lexical_unit')\n",
    "        \n",
    "createDirectories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function that receives a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framesPerCategory(categories, files, opt, path):\n",
    "    mensagem = \"Dados de: \\n\"\n",
    "    exc_data = dict()\n",
    "    if(opt == 'all'):\n",
    "        categories = list([opt])\n",
    "    for cat in categories:\n",
    "            dchart = dict()\n",
    "            #dexcel = dict()\n",
    "            for file_dir in files:\n",
    "                abstract = getInfoFromFile(path+'/'+file_dir)\n",
    "                if(abstract.get(opt) == cat):\n",
    "                    file = open(path+'/'+file_dir,\"r\").readlines()\n",
    "                    for line in file:\n",
    "                        jsonline = json.loads(line)\n",
    "                        for frame in jsonline.get('frames'):\n",
    "                            frameNom = frame.get('target').get('name')\n",
    "                            if(dchart.get(frameNom) != None):\n",
    "                                dchart[frameNom] += 1\n",
    "                            else:\n",
    "                                dchart[frameNom] = 1\n",
    "            dchart = sortDict(dchart)\n",
    "            if(dchart):\n",
    "                exc_data[cat] = dchart.copy()\n",
    "                generateChart(dchart, opt, cat, 'frame')\n",
    "            else:\n",
    "                mensagem = mensagem+cat+\"\\n\"\n",
    "    mensagem = mensagem+\"não encontrados\"\n",
    "    if(mensagem != \"Dados de: \\n\"+\"não encontrados\"):\n",
    "        print(mensagem)\n",
    "    return exc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fElementsPerCategory(categories, files, opt, path):\n",
    "    mensagem = \"Dados de: \\n\"\n",
    "    exc_data = dict()\n",
    "    if(opt == 'all'):\n",
    "        categories = list([opt])\n",
    "    for cat in categories:\n",
    "            dchart = dict()\n",
    "            #dexcel = dict()\n",
    "            for file_dir in files:\n",
    "                abstract = getInfoFromFile(path+'/'+file_dir)\n",
    "                if(abstract.get(opt) == cat):\n",
    "                    file = open(path+'/'+file_dir,\"r\").readlines()\n",
    "                    for line in file:\n",
    "                        jsonline = json.loads(line)\n",
    "                        for frame in jsonline.get('frames'):\n",
    "                            for span in frame.get('target').get('spans'):\n",
    "                                    LUnom = span.get('text')\n",
    "                                    if(dchart.get(LUnom) != None):\n",
    "                                        dchart[LUnom] += 1\n",
    "                                    else:\n",
    "                                        dchart[LUnom] = 1\n",
    "#                             for anno in frame.get('annotationSets'):\n",
    "#                                 for felement in anno.get('frameElements'):\n",
    "#                                     elementnom = felement.get('name')\n",
    "#                                     if(dchart.get(elementnom) != None):\n",
    "#                                         dchart[elementnom] += 1\n",
    "#                                     else:\n",
    "#                                         dchart[elementnom] = 1\n",
    "            dchart = sortDict(dchart)\n",
    "            if(dchart):\n",
    "                exc_data[cat] = dchart.copy()\n",
    "                generateChart(dchart, opt, cat+\" (Lexical Units)\", 'lexical_unit')\n",
    "            else:\n",
    "                mensagem = mensagem+cat+\"\\n\"\n",
    "    mensagem = mensagem+\"não encontrados\"\n",
    "    if(mensagem != \"Dados de: \\n\"+\"não encontrados\"):\n",
    "        print(mensagem)\n",
    "    return exc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateExcel(fpcat, opt, optdir):\n",
    "    if(opt != \"all\"):\n",
    "        for v in fpcat:\n",
    "            vDict = fpcat.get(v)\n",
    "            vDF = pd.DataFrame({optdir+'s':list(vDict.keys()),'occurrence':list(vDict.values())})\n",
    "            vDF.to_excel(\"export/\"+opt+\"/\"+optdir+\"/\"+v+\".xlsx\", index=False)\n",
    "    else:\n",
    "        fpcat = pd.DataFrame({optdir+'s':list(fpcat.get('all').keys()),'occurrence':list(fpcat.get('all').values())})\n",
    "        fpcat.to_excel(\"export/\"+opt+\"/\"+optdir+\"/All_Abstracts.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## selecting only the files we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dictionaryFields' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-97fd96afbe2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcleanDirectory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionaryFields\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dictionaryFields' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"../semafor_output\" #./semafor_output\n",
    "files = os.listdir(path)\n",
    "cleanDirectory(files) \n",
    "a = dictionaryFields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de: \n",
      "ADVANCES IN AGRONOMY, VOL 136\n",
      "QUALITY & SAFETY\n",
      "não encontrados\n",
      "Dados de: \n",
      "ADVANCES IN AGRONOMY, VOL 136\n",
      "QUALITY & SAFETY\n",
      "não encontrados\n"
     ]
    }
   ],
   "source": [
    "#sorting fields alphabetically\n",
    "fields = list(getAllFields())\n",
    "fields.sort()\n",
    "\n",
    "#sorting disciplines alphabetically\n",
    "disciplines = list(getAllDisciplines())\n",
    "disciplines.sort()\n",
    "\n",
    "#sorting journals alphabetically\n",
    "journals = list(getAllJournals())\n",
    "journals.sort()\n",
    "\n",
    "#creating the directories needed\n",
    "createDirectories()\n",
    "\n",
    "# bar charts for all abstracts, by field, by discipline and by journal\n",
    "fpall = framesPerCategory(files,files,'all',path)\n",
    "fpfields = framesPerCategory(fields,files,'field',path)\n",
    "fpdisciplines = framesPerCategory(disciplines,files,'discipline',path)\n",
    "fpjournal = framesPerCategory(journals,files,'journal',path)\n",
    "\n",
    "#FEpall = fElementsPerCategory(files,files,'all',path)\n",
    "FEpfields = fElementsPerCategory(fields,files,'field',path)\n",
    "FEpdisciplines = fElementsPerCategory(disciplines,files,'discipline',path)\n",
    "FEpjournals = fElementsPerCategory(journals,files,'journal',path)\n",
    "\n",
    "#xls files for all abstracts, by field, by discipline and by journal\n",
    "#generateExcel(fpall,\"all\",'frame')\n",
    "generateExcel(fpfields,\"field\",'frame')\n",
    "generateExcel(fpdisciplines,\"discipline\",'frame')\n",
    "generateExcel(fpjournal,\"journal\",'frame')\n",
    "\n",
    "#xls files for all abstracts, by field, by discipline and by journal (frame elements)\n",
    "#generateExcel(FEpall,\"all\",'lexical_unit')\n",
    "generateExcel(FEpfields,\"field\",'lexical_unit')\n",
    "generateExcel(FEpdisciplines,\"discipline\",'lexical_unit')\n",
    "generateExcel(FEpjournals,\"journal\",'lexical_unit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantifica os frames que aparecem em cada categoria, maximo 3 (que é o que queremos)\n",
    "def countFramesInCat(fpcat,indict):\n",
    "    for item in fpcat:\n",
    "        for f in first30(fpcat.get(item).copy()):\n",
    "            if(indict.get(f) != None):\n",
    "                indict[f] += 1\n",
    "            else:\n",
    "                indict[f] = 1 \n",
    "    return indict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove os frames que apareceram em menos que três(todas) disciplines\n",
    "def getinfirst30(indict,limit):\n",
    "    keys = list(indict.keys())\n",
    "    for key in keys:\n",
    "        if(indict.get(key) < limit):\n",
    "            indict.pop(key)\n",
    "    return indict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#somando as ocorrencias dos frames que estao entre os 30 em todos, em cada um dos items de categoria\n",
    "def suminfirst30occurrences(indict, fpcatdict, out):\n",
    "    for oc in indict.copy():\n",
    "        for u in fpcatdict.copy():\n",
    "            for p in fpcatdict.get(u).copy():\n",
    "                if(p == oc):\n",
    "                    if(out.get(oc) != None):\n",
    "                        out[oc] = out[p]+fpcatdict.get(u).copy().get(p)\n",
    "                    else:\n",
    "                        out[oc] = fpcatdict.get(u).copy().get(p)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inall = dict()\n",
    "indisciplines = dict()\n",
    "infields = dict()\n",
    "injournals = dict()\n",
    "\n",
    "inFEall = dict()\n",
    "inFEdisciplines = dict()\n",
    "inFEfields = dict()\n",
    "inFEjournals = dict()\n",
    "\n",
    "indisciplines = countFramesInCat(fpdisciplines,indisciplines)\n",
    "infields = countFramesInCat(fpfields,infields)\n",
    "injournals = countFramesInCat(fpjournal,injournals)\n",
    "\n",
    "#test frame LU\n",
    "inFEdisciplines = countFramesInCat(FEpdisciplines,inFEdisciplines)\n",
    "inFEfields = countFramesInCat(FEpfields,inFEfields)\n",
    "inFEjournals = countFramesInCat(FEpjournals,inFEjournals)\n",
    "            \n",
    "#sorting\n",
    "inall = sortDict(inall)\n",
    "\n",
    "infields = sortDict(infields)\n",
    "indisciplines = sortDict(indisciplines)\n",
    "injournals = sortDict(injournals)\n",
    "\n",
    "inFEfields = sortDict(inFEfields)\n",
    "inFEdisciplines = sortDict(inFEdisciplines)\n",
    "inFEjournals = sortDict(inFEjournals)\n",
    "\n",
    "indisciplines = getinfirst30(indisciplines,3)\n",
    "infields = getinfirst30(infields,10)\n",
    "#excecao aqui, mais da metade, nao todos\n",
    "injournals = getinfirst30(injournals,29)\n",
    "\n",
    "inFEdisciplines = getinfirst30(inFEdisciplines,3)\n",
    "inFEfields = getinfirst30(inFEfields,10)\n",
    "#excecao aqui, mais da metade, nao todos\n",
    "inFEjournals = getinfirst30(inFEjournals,29)\n",
    "\n",
    "\n",
    "sumin30disciplines = dict()\n",
    "sumin30fields = dict()\n",
    "sumin30journals = dict()\n",
    "\n",
    "suminFE30disciplines = dict()\n",
    "suminFE30fields = dict()\n",
    "suminFE30journals = dict()\n",
    "\n",
    "#soma o valor das ocorrencias dos que aparecem em todas (que ja foram selecionados)\n",
    "sumin30disciplines = suminfirst30occurrences(indisciplines, fpdisciplines, sumin30disciplines)\n",
    "sumin30fields = suminfirst30occurrences(infields, fpfields, sumin30fields)\n",
    "sumin30journals = suminfirst30occurrences(injournals, fpjournal, sumin30journals)\n",
    "\n",
    "#sorting\n",
    "sumin30disciplines = sortDict(sumin30disciplines)\n",
    "sumin30fields = sortDict(sumin30fields)\n",
    "sumin30journals = sortDict(sumin30journals)\n",
    "\n",
    "#plotando\n",
    "generateChart(sumin30disciplines,'discipline','Occurrence of frames in the 30 with more occurrence for all Disciplines','frame')\n",
    "sumin30disciplinesDF = pd.DataFrame({'Frames':list(sumin30disciplines.keys()),'Occurrence':list(sumin30disciplines.values())})\n",
    "sumin30disciplinesDF.to_excel(\"export/discipline/frame/\"+\"summary\"+\".xlsx\", index=False)\n",
    "                         \n",
    "generateChart(sumin30fields,'field','Occurrence of frames in the 30 with more occurrence for all Fields','frame')\n",
    "sumin30fieldsDF = pd.DataFrame({'Frames':list(sumin30fields.keys()),'Occurrence':list(sumin30fields.values())})\n",
    "sumin30fieldsDF.to_excel(\"export/field/frame/\"+\"summary\"+\".xlsx\", index=False)\n",
    "        \n",
    "generateChart(sumin30journals,'journal','Occurrence of frames in the 30 with more occurrence for more than half of journals','frame')\n",
    "sumin30journalsDF = pd.DataFrame({'Frames':list(sumin30journals.keys()),'Occurrence':list(sumin30journals.values())})\n",
    "sumin30journalsDF.to_excel(\"export/journal/frame/\"+\"summary\"+\".xlsx\", index=False)\n",
    "        \n",
    "# #excecao\n",
    "generateChart(injournals,'journal','Number of journals for frames in the 30 with more occurrence for more than half of journals','frame')\n",
    "sumin30journalsDF = pd.DataFrame({'Frames':list(sumin30journals.keys()),'Occurrence':list(sumin30journals.values())})\n",
    "sumin30journalsDF.to_excel(\"export/journal/frame/\"+\"summary_counting\"+\".xlsx\", index=False)\n",
    "\n",
    "#soma o valor das ocorrencias dos que aparecem em todas (que ja foram selecionados)\n",
    "suminFE30disciplines = suminfirst30occurrences(inFEdisciplines, FEpdisciplines, suminFE30disciplines)\n",
    "suminFE30fields = suminfirst30occurrences(inFEfields, FEpfields, suminFE30fields)\n",
    "suminFE30journals = suminfirst30occurrences(inFEjournals, FEpjournals, suminFE30journals)\n",
    "\n",
    "#sorting\n",
    "suminFE30disciplines = sortDict(suminFE30disciplines)\n",
    "suminFE30fields = sortDict(suminFE30fields)\n",
    "suminFE30journals = sortDict(suminFE30journals)\n",
    "\n",
    "#plotando\n",
    "if(suminFE30disciplines):\n",
    "    generateChart(suminFE30disciplines,'discipline','Occurrence of Lexical Units in the 30 with more occurrence for all Disciplines','lexical_unit')\n",
    "    suminFE30disciplinesDF = pd.DataFrame({'Lexical Units':list(suminFE30disciplines.keys()),'Occurrence':list(suminFE30disciplines.values())})\n",
    "    suminFE30disciplinesDF.to_excel(\"export/discipline/lexical_unit/\"+\"summary\"+\".xlsx\", index=False)\n",
    "                  \n",
    "if(suminFE30fields):\n",
    "    generateChart(suminFE30fields,'field','Occurrence of Lexical Units in the 30 with more occurrence for all Fields','lexical_unit')\n",
    "    suminFE30fieldsDF = pd.DataFrame({'Lexical Units':list(suminFE30fields.keys()),'Occurrence':list(suminFE30fields.values())})\n",
    "    suminFE30fieldsDF.to_excel(\"export/field/lexical_unit/\"+\"summary\"+\".xlsx\", index=False)\n",
    "        \n",
    "if(suminFE30journals):\n",
    "    generateChart(suminFE30journals,'journal','Occurrence of Lexical Units in the 30 with more occurrence for more than half of journals','lexical_unit')\n",
    "    suminFE30journalsDF = pd.DataFrame({'Lexical Units':list(suminFE30journals.keys()),'Occurrence':list(suminFE30journals.values())})\n",
    "    suminFE30journalsDF.to_excel(\"export/journal/lexical_unit/\"+\"summary\"+\".xlsx\", index=False)\n",
    "        \n",
    "# #excecao\n",
    "if(inFEjournals):\n",
    "    generateChart(inFEjournals,'journal','Number of journals for Lexical Units in the 30 with more occurrence for more than half of journals','lexical_unit')\n",
    "    suminFE30journalsDF = pd.DataFrame({'Lexical Units':list(suminFE30journals.keys()),'Occurrence':list(suminFE30journals.values())})\n",
    "    suminFE30journalsDF.to_excel(\"export/journal/lexical_unit/\"+\"summary_counting\"+\".xlsx\", index=False)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Quantity': {}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #Biblioteca de suporte de arrays e matriz multidimensionais\n",
    "import pandas as pd #Biblioteca de manipulação e análise de dado\n",
    "import os #Esse modulo prove alguns metodos para atuar com o sistema operacional, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import sys #Esse modulo prove acesso à algumas variaveis de sistema, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import matplotlib.pyplot as plt #Biblioteca padrão pala plotagem de graficos\n",
    "import seaborn as sns #Biblioteca para melhoria de interface dos graficos\n",
    "sys.path.append('../abstract_normalizer')\n",
    "import dictionaries\n",
    "import json\n",
    "import operator\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "import math\n",
    "\n",
    "path = \"../semafor_output\" #./semafor_output\n",
    "files = os.listdir(path)\n",
    "cleanDirectory(files)\n",
    "\n",
    "dict_frames = dict()\n",
    "for file_dir in files:\n",
    "    abstract = getInfoFromFile(path+'/'+file_dir)\n",
    "    file = open(path+'/'+file_dir,\"r\").readlines()\n",
    "    for line in file:\n",
    "        jsonline = json.loads(line)\n",
    "        for frame in jsonline.get('frames'):\n",
    "            if(frame.get('target').get('name') == 'Scrutinity' or frame.get('target').get('name') == 'Quantity'): \n",
    "                \n",
    "                if(dict_frames.get(frame.get('target').get('name')) == None):\n",
    "                    dict_frames[frame.get('target').get('name')] = dict()\n",
    "                    \n",
    "                for span in frame.get('target').get('spans') :\n",
    "                    lutext= span.get('text')\n",
    "                    #if(dict_frames.get(frame.get('target').get('name')).get(lutext) != None):\n",
    "                        #lus[frame.get('target').get('name')][lutext] += 1\n",
    "                    #else:\n",
    "                        #lus[frame.get('target').get('name')][lutext] = 1\n",
    "                            \n",
    "dict_frames = sortDict(dict_frames)\n",
    "print(dict_frames)\n",
    "\n",
    "#sumin30journalsDF = pd.DataFrame({'lexical_unit':list(lus.keys()), 'occurrences':list(lus.values())})\n",
    "#.to_excel(\"export/\"+\"Cardinal_numbers_biological_sciences\"+\".xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sla'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = dict()\n",
    "teste['bbb'] = 'sla'\n",
    "a = teste.get('bbb')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
