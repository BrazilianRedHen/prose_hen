{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento de codigo\n",
    "Apos o recebmento dos arquivos CONLL, foi feito a separação dos arquivos em suas determinadas revistas, em seguida foram separados os arquivos para as pastas separadas por areas de conhecimento. Apos esse processo foi iniciado o processo de codificação de uma atraves da plataforma JUPYTER para extrair as informações em arquivos ais facilmentes editaveis. Para isso forom utiizadas as segintes bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np #Biblioteca de suporte de arrays e matriz multidimensionais\n",
    "import pandas as pd #Biblioteca de manipulação e análise de dado\n",
    "import os #Esse modulo prove alguns metodos para atuar com o sistema operacional, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import sys #Esse modulo prove acesso à algumas variaveis de sistema, nesse projeto utilizado para gerenciamento de diretorios\n",
    "import matplotlib.pyplot as plt #Biblioteca padrão pala plotagem de graficos\n",
    "import seaborn as sns #Biblioteca para melhoria de interface dos graficos\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento de funções.\n",
    "    Em seguida foi desenvolvido o codigo necessario para a transformação dos arquivos CONLL em arquivos com dados analisaeis, seguindo as orientções de requisitos.\n",
    "\n",
    "## getListCount\n",
    "    Essa função recebe uma matriz de dados(df) e retorna uma lista com a contagem de inicidencia de uma coluna especifica(title).\n",
    "    Utilizada para fazer a contagem dos frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getListCount(df,title):\n",
    "    listOfterms = df[title].value_counts()\n",
    "    return listOfterms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# returnHeaderAndContent\n",
    "    Essa função recebe uma matriz de dados (df) retorna duas matrizes, uma com todos os dados referentes a primeira sentença  e outro com o restante do conteudo da matriz\n",
    "    Essa função é executada duas vezes, uma vez para separar o titulo da revista e o resumo todo e em seguida o titulo do resumo e o conteudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def returnHeaderAndContent(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if(index != row['ID']-1):\n",
    "            index_title = index\n",
    "            break\n",
    "    temp = index_title\n",
    "    count = temp\n",
    "    while temp == count:\n",
    "        if(df.iloc[temp-1]['FORM'] != df.iloc[index_title-1]['FORM']):\n",
    "            break\n",
    "        count = count + index_title\n",
    "        temp  = temp + index_title\n",
    "    return  df.iloc[:temp-index_title].reset_index(drop=True), df.iloc[temp-index_title:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getPlot\n",
    "Essa função recebe uma matriz de dados(df), um nome de uma coluna(label),e o nome do arquivo a ser salvo(filename).\n",
    "Ele gera um grafico dos dados da matriz e salva esse grafico com o nome especificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPlot(df,label,fileName):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(23, 10))\n",
    "    fig.subplots_adjust(bottom=0.4)\n",
    "    plt.xticks(rotation=70)\n",
    "    try:\n",
    "        ax = sns.barplot(x=\"index\", y=label, data=df)\n",
    "        fig.savefig(fileName)\n",
    "    except:\n",
    "        print(\"\")\n",
    "        \n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  getData(dt):\n",
    "    dfa = pd.DataFrame(columns=[\"ns\",\"ne\",\"token\",\"target_name\"])\n",
    "    ns = 0\n",
    "    for index, row in dt.iterrows():\n",
    "        ne=1\n",
    "        for token in row[\"tokens\"]:\n",
    "            dff = pd.DataFrame(columns=[\"ns\",\"ne\",\"token\"],data=[[ns,ne,token]])\n",
    "            dfa = dfa.append(dff).reset_index(drop=True)\n",
    "            ne  = ne+1\n",
    "        for frame in row[\"frames\"]:\n",
    "            ne    = json_normalize(json_normalize(frame)[\"target.spans\"][0])[\"end\"]\n",
    "            text   = json_normalize(json_normalize(frame)[\"target.spans\"][0])[\"text\"]\n",
    "            target = json_normalize(frame)[\"target.name\"][0]\n",
    "            dfa.loc[(dfa['ns'] == ns) & (dfa['ne'] == ne[0]) , 'target_name'] = target\n",
    "        ns = ns+1\n",
    "    return dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "def getCloudWord(df,filen):\n",
    "    dic ={}\n",
    "    for index, row in df.iterrows():\n",
    "        dic.update({row[\"index\"]:row[\"target_name\"]})\n",
    "    wc = WordCloud().generate_from_frequencies(dic)\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    fig = plt.figure(figsize=(23, 10))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(filen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de extração dos dados\n",
    "## Listagem e criação de pastas\n",
    "    Utilizando a pasta do arquivo atual como base, inicialmente são listados todos os arquivos dessa pasta e adicionado na variavel directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \".\"\n",
    "directories = os.listdir( path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de pastas não utilizadas\n",
    "    São retirados os arquivos e diretorios que não são relevantes para a analise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleanDirectory():\n",
    "    try:\n",
    "        for directory in directories:\n",
    "            if(directory.startswith(\".\") or directory.endswith(\".ipynb\") or directory.endswith(\".png\") ):\n",
    "                directories.remove(directory)\n",
    "                cleanDirectory()\n",
    "    except:\n",
    "        print(\"\")\n",
    "cleanDirectory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de dados\n",
    "\n",
    "    É criado um laço de repetição passando por todos os diretorios do diretorio base e listado todos os arquivos desse diretorio que possuem a extensão CONLL.\n",
    "    Dessa nova lista tambem é criado um novo laço de repetição para cada arquivo gera uma matriz que possue todos os dados do arquivo CONLL utilizando a função returnHeaderAndContent é possivel separar o titulo do journal do conteudo do resumo. Apos isso utilizando novamente a função returnHeaderAndContent é possivel separar o titulo do resumo do seu conteudo e separalos em matrizes diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "_COMPUTER//ieee-transactions-on-medical//2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2015-2482920_ieee-transactions-on-medical-imaging_roth_holger.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2015-2482920_ieee-transactions-on-medical-imaging_roth_holger.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2016-2526689_ieee-transactions-on-medical-imaging_van-grinsven_mark.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2015-2482920_ieee-transactions-on-medical-imaging_roth_holger.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2016-2526689_ieee-transactions-on-medical-imaging_van-grinsven_mark.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-jan_JA_10-1109_TMI-2015-2458702_ieee-transactions-on-medical-imaging_xu_jun.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json\n",
      "_COMPUTER//ieee-transactions-on-medical//2016-may_JA_10-1109_TMI-2015-2482920_ieee-transactions-on-medical-imaging_roth_holger.seg.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7d936e3badfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistOfFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mdf_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mdf_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mdf_head\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ns\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-815b1820229c>\u001b[0m in \u001b[0;36mgetData\u001b[0;34m(dt)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mne\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mdff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ns\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ne\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mdfa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mne\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mne\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     mgr = _arrays_to_mgr(arrays, columns, index, columns,\n\u001b[0;32m--> 318\u001b[0;31m                                          dtype=dtype)\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   5401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5402\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5403\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5405\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   5712\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5713\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 5714\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   5715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5716\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2875\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2877\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path)\u001b[0m\n\u001b[1;32m   2836\u001b[0m         \u001b[0;31m# perf shortcut as this is the most common case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_fast_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2838\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0m_possibly_castable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chrono/anaconda2/lib/python2.7/site-packages/pandas/types/cast.pyc\u001b[0m in \u001b[0;36m_possibly_castable\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_DATELIKE_DTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_POSSIBLY_CAST_DTYPES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "columns = [\"ns\",\"ne\",\"token\",\"target_name\"]\n",
    "df_all_sum = pd.DataFrame(columns=columns)\n",
    "df_head_sum = pd.DataFrame(columns=columns)\n",
    "df_content_sum = pd.DataFrame(columns=columns)\n",
    "df_title_sum  = pd.DataFrame(columns=columns)\n",
    "df_tempo  = pd.DataFrame(columns=columns)\n",
    "for directory in directories:\n",
    "    try:\n",
    "        makeDir = \"..//exportsOfAbstracts//Disciplines//\"+directory\n",
    "        os.makedirs( makeDir );\n",
    "    except:\n",
    "        print(\"-\")\n",
    "    subDirectories = os.listdir( directory+\"//\" )\n",
    "    for subDirectory in subDirectories:\n",
    "        columns = ['ID', 'FORM' ,'LEMMA' ,'PLEMMA' ,'POS' ,'PPOS' ,\n",
    "           'FEAT' ,'PFEAT' ,'HEAD' ,'PHEAD' ,'DEPREL' ,'PDEPREL','FILLPRED','PRED','APRED']\n",
    "        listOfFiles = []\n",
    "        folderPath = \"{}\".format(directory+\"//\"+subDirectory)\n",
    "        \n",
    "        files = os.listdir(folderPath)\n",
    "        for fl in files:\n",
    "            if(fl.endswith('.json')):\n",
    "                listOfFiles.append(\"{}//{}\".format(folderPath,fl))\n",
    "        for i in listOfFiles:\n",
    "            print(i)\n",
    "            df_all = getData(pd.read_json(i, lines=True))\n",
    "            df_title = df_all[df_all[\"ns\"]==0]\n",
    "            df_head =  df_all[df_all[\"ns\"]==1]\n",
    "            df_content = df_all[df_all[\"ns\"]>1]\n",
    "            df_title_sum =   df_title_sum.append(df_title)\n",
    "            #df_tempo = df_head.append(df_content)\n",
    "            df_all_sum =     df_all_sum.append(df_all) \n",
    "            df_head_sum =    df_head_sum.append(df_head) \n",
    "            df_content_sum = df_content_sum.append(df_content)\n",
    "    filePath = \"..//exportsOfAbstracts//Disciplines//\"+directory+\"//\"+directory\n",
    "    list_all = getListCount(df_all_sum,'target_name')[1:].to_frame().reset_index()\n",
    "    list_head  = getListCount(df_head_sum,'target_name')[1:].to_frame().reset_index()\n",
    "    list_content = getListCount(df_content_sum,'target_name')[1:].to_frame().reset_index()\n",
    "    list_all.to_excel(filePath+\"_list_all.xls\", index = None, header=True)\n",
    "    \n",
    "    getPlot(list_all,\"target_name\",filePath+\"_all.png\")\n",
    "    list_head.to_excel(filePath+\"_list_head.xls\", index = None, header=True)\n",
    "    getPlot(list_head,\"target_name\",filePath+\"_head.png\")\n",
    "    list_content.to_excel(filePath+\"_list_content.xls\", index = None, header=True)\n",
    "    getPlot(list_content,\"target_name\",filePath+\"_content.png\")\n",
    "    getCloudWord(list_all,filePath+\"_cloud_word_all.png\")\n",
    "    getCloudWord(list_head,filePath+\"cloud_word_head.png\")\n",
    "    getCloudWord(list_content,filePath+\"cloud_word_content.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando essas matrizes recem criadas é utilizada a função getListCount para obter a contagem dos frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_all = getListCount(df_all_sum,'PRED')[1:].to_frame().reset_index()\n",
    "list_head  = getListCount(df_head_sum,'PRED')[1:].to_frame().reset_index()\n",
    "list_content = getListCount(df_content_sum,'PRED')[1:].to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apos a criação da lista de abstracts foi utilizada a função da biblioteca do pandas to_excel para criar o documento de cada uma das listas. E finalizando tambem foi criado os graficos de cada uma das listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_all.to_excel(\"_list_all.xls\", index = None, header=True)\n",
    "getPlot(list_all,\"PRED\",\"_all.png\")\n",
    "list_head.to_excel(\"_list_head.xls\", index = None, header=True)\n",
    "getPlot(list_head,\"PRED\",\"_head.png\")\n",
    "list_content.to_excel(\"_list_content.xls\", index = None, header=True)\n",
    "getPlot(list_content,\"PRED\",\"_content.png\")\n",
    "getCloudWord(list_all,\"wc_content_all.png\")\n",
    "getCloudWord(list_head,\"wc_content_head.png\")\n",
    "getCloudWord(list_content,\"wc_content_content.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "['2015-sep_JA_10-1109_TMI-2015-2409024_ieee-transactions-on-medical-imaging_zhao_yitian.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2015-2482920_ieee-transactions-on-medical-imaging_roth_holger.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2526689_ieee-transactions-on-medical-imaging_van-grinsven_mark.seg.json',\n",
    " '2016-jan_JA_10-1109_TMI-2015-2458702_ieee-transactions-on-medical-imaging_xu_jun.seg.json',\n",
    " 'desktop.ini',\n",
    " '2016-may_JA_10-1109_TMI-2016-2535302_ieee-transactions-on-medical-imaging_tajbakhsh_nima.seg.json',\n",
    " '2016-may_JA_10-1109_TMI-2016-2528129_ieee-transactions-on-medical-imaging_dou.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2548501_ieee-transactions-on-medical-imaging_moeskops_pim.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2536809_ieee-transactions-on-medical-imaging_setio_arnaud.seg.json', \n",
    " '2015-may_JA_10-1109_TMI-2014-2375065_ieee-transactions-on-medical-imaging_ferguson_matthew.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2538465_ieee-transactions-on-medical-imaging_pereira_sergio.seg.json', \n",
    " '2016-nov_JA_10-1109_TMI-2016-2546227_ieee-transactions-on-medical-imaging_liskowski_pawel.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2525803_ieee-transactions-on-medical-imaging_sirinukunwattana_korsuk.seg.json',\n",
    " '2015-feb_JA_10-1109_TMI-2014-2359650_ieee-transactions-on-medical-imaging_christensen-jeffries_kirsten.seg.json',\n",
    " '2016-jan_JA_10-1109_TMI-2015-2457891_ieee-transactions-on-medical-imaging_li_qiaoliang.seg.json',\n",
    " '2015-nov_JA_10-1109_TMI-2015-2428634_ieee-transactions-on-medical-imaging_demene_charlie.seg.json', \n",
    " '2015-oct_JA_10-1109_TMI-2014-2377694_ieee-transactions-on-medical-imaging_menze_bjoern.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2528162_ieee-transactions-on-medical-imaging_shin_hoo-chang.seg.json',\n",
    " '2015-feb_JA_10-1109_TMI-2014-2361481_ieee-transactions-on-medical-imaging_zhang_xiaofan.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2535865_ieee-transactions-on-medical-imaging_anthimopoulos_marios.seg.json', \n",
    " '2016-may_JA_10-1109_TMI-2016-2532122_ieee-transactions-on-medical-imaging_kallenberg_michiel.seg.json']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
